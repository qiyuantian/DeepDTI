
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>s_DeepDTI_prepData</title><meta name="generator" content="MATLAB 9.4"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2021-07-14"><meta name="DC.source" content="s_DeepDTI_prepData.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#1">introduction</a></li><li><a href="#2">load data</a></li><li><a href="#3">select optimized encoding directions</a></li><li><a href="#4">generate input data of CNN</a></li><li><a href="#5">generate ground-truth data of CNN</a></li><li><a href="#6">save data</a></li></ul></div><h2 id="1">introduction</h2><pre class="codeinput"><span class="comment">% s_DeepDTI_prepData.m</span>
<span class="comment">%</span>
<span class="comment">%   A script for preparing input and output data for convolutional neural</span>
<span class="comment">%   network in DeepDTI.</span>
<span class="comment">%</span>
<span class="comment">%   Source code:</span>
<span class="comment">%       https://github.com/qiyuantian/DeepDTI/blob/main/s_DeepDTI_prepData.m</span>
<span class="comment">%</span>
<span class="comment">%   HTML file can be automatically generaged using command:</span>
<span class="comment">%       publish('s_DeepDTI_prepData.m', 'html');</span>
<span class="comment">%</span>
<span class="comment">%   Reference:</span>
<span class="comment">%       [1] Tian Q, Bilgic B, Fan Q, Liao C, Ngamsombat C, Hu Y, Witzel T,</span>
<span class="comment">%       Setsompop K, Polimeni JR, Huang SY. DeepDTI: High-fidelity</span>
<span class="comment">%       six-direction diffusion tensor imaging using deep learning.</span>
<span class="comment">%       NeuroImage. 2020;219:117017.</span>
<span class="comment">%</span>
<span class="comment">%       [2] Tian Q, Li Z, Fan Q, Ngamsombat C, Hu Y, Liao C, Wang F,</span>
<span class="comment">%       Setsompop K, Polimeni JR, Bilgic B, Huang SY. SRDTI: Deep</span>
<span class="comment">%       learning-based super-resolution for diffusion tensor MRI. arXiv</span>
<span class="comment">%       preprint. 2021; arXiv:2102.09069.</span>
<span class="comment">%</span>
<span class="comment">% (c) Qiyuan Tian, Harvard, 2021</span>
</pre><h2 id="2">load data</h2><pre class="codeinput">clear, clc, close <span class="string">all</span>

tmp = load(<span class="string">'data.mat'</span>); <span class="comment">% example data was saved in unit16 to save sapce to be shared on Github.</span>
data = double(tmp.data); <span class="comment">% 18 b = 0 volumes and 90 dwi volumes</span>
<span class="comment">% due to size limit of github, only 70 axial slices are used here as</span>
<span class="comment">% example data. actual implementation should use whole brain data.</span>
<span class="comment">% diffusion data were corrected for intensity bias already, which can be</span>
<span class="comment">% performed for new data using dwibiascorrect function from MRtrix3:</span>
<span class="comment">% https://mrtrix.readthedocs.io/en/latest/reference/commands/dwibiascorrect.html</span>
<span class="comment">% we did not evaluate the effects of bias on the performance of CNN, but do</span>
<span class="comment">% not expect significant difference in results.</span>
bvals = tmp.bvals; <span class="comment">% b = 1000 s/mm^2</span>
bvecs = tmp.bvecs;
mask = tmp.mask;

b0s = data(:, :, :, bvals &lt; 100); <span class="comment">% all 18 b = 0 images</span>
meanb0 = mean(b0s, 4); <span class="comment">% mean b = 0 images</span>
dwis = data(:, :, :, bvals &gt; 100); <span class="comment">% all 90 dwis</span>
bvals_dwi = bvals(bvals &gt; 100); <span class="comment">% bvals for dwis</span>
bvecs_dwi = bvecs(bvals &gt; 100, :); <span class="comment">% bvecs for dwis</span>

dirs = bvecs(bvals &gt; 100, :); <span class="comment">% 90 diffusion-encoding directions</span>
dirs_vis = dirs .* sign(dirs(:, 3)); <span class="comment">% directions flipped to z &gt; 0 for visualization</span>
sz_data = size(data);

figure; <span class="comment">% display image data</span>
subplot(1, 2, 1)
imshow(rot90(data(:, :, 35, 1)), [0, 10000])
title(<span class="string">'b = 0 image'</span>);
subplot(1, 2, 2)
imshow(rot90(data(:, :, 35, 2)), [0, 4000])
title(<span class="string">'diffusion weighted image'</span>);

figure; <span class="comment">% display diffusion encoding directions, all flipped to z &gt; 0</span>
plot3(dirs_vis(:, 1), dirs_vis(:, 2), dirs_vis(:, 3), <span class="string">'.'</span>);
grid <span class="string">on</span>, axis <span class="string">equal</span>
zlim([-1, 1])
title(<span class="string">'90 diffusion encoding directions'</span>);
</pre><img vspace="5" hspace="5" src="s_DeepDTI_prepData_01.png" alt=""> <img vspace="5" hspace="5" src="s_DeepDTI_prepData_02.png" alt=""> <h2 id="3">select optimized encoding directions</h2><pre class="codeinput"><span class="comment">% 6 optimized directions from the DSM scheme that minimize the condition</span>
<span class="comment">% number of the diffusion tensor transformation matrix while are as uniform</span>
<span class="comment">% as possible. from S Skare et al., J Magn Reson. 2000;147(2):340-52.</span>
dsm6 = [0.91, 0.416, 0; <span class="keyword">...</span>
               0, 0.91, 0.416; <span class="keyword">...</span>
               0.416, 0, 0.91; <span class="keyword">...</span>
               0.91, -0.416, 0; <span class="keyword">...</span>
               0, 0.91, -0.416; <span class="keyword">...</span>
              -0.416, 0, 0.91];

dsm6_norm = dsm6 ./ sqrt(dsm6(:, 1) .^ 2 + dsm6(:, 2) .^ 2 + dsm6(:, 3) .^ 2); <span class="comment">% normalize vectors</span>

<span class="comment">% randomly rotate the DSM6 dirs, select their nearest 6 dirs from acquired</span>
<span class="comment">% dirs, keep those with low condition number and angel difference.</span>
rotang_all = [];
angerr_all  = [];
condnum_all = [];
ind_all = [];
<span class="keyword">for</span> ii = 1 : 100000 <span class="comment">% number of iterations can be increased in actual implementation</span>

    rotangs = rand(1, 3) * 2 * pi; <span class="comment">% random angles to rotate around x, y, z axis</span>
    R = rot3d(rotangs); <span class="comment">% rotation matrix</span>
    dsm6_rot = (R * dsm6_norm')'; <span class="comment">% roated directions</span>

    <span class="comment">% find 6 nearest dirs in acquired dirs</span>
    angerrors = acosd(abs(dsm6_rot * dirs')); <span class="comment">% angles btw rotated DSM6 dirs and acquired dirs</span>
    [minerrors, ind] = min(angerrors, [], 2); <span class="comment">% 6 dirs with min angles compared to rotated DSM6 dirs</span>

    meanangerr = mean(minerrors); <span class="comment">% mean angle errors of selected dirs</span>
    condnum = cond(amatrix(dirs(ind, :))); <span class="comment">% cond number of tensor tx matrix of selected dirs</span>

    <span class="keyword">if</span> meanangerr &lt; 5 &amp;&amp; condnum &lt; 1.6 <span class="comment">% only use dirs with low angle error and cond number</span>
        <span class="keyword">if</span> isempty(ind_all) || ~any(sum(ind_all == sort(ind'), 2) == 6) <span class="comment">% make sure no repetition</span>

            <span class="comment">% record params for satisfied sets</span>
            angerr_all = cat(1, angerr_all, meanangerr);
            condnum_all = cat(1, condnum_all, condnum);
            ind_all = cat(1, ind_all, sort(ind'));
            rotang_all = cat(1, rotang_all, rotangs);
        <span class="keyword">end</span>
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="comment">% here only select 5 sets of directions with lowest condition number</span>
<span class="comment">% better to make sure all dwis can be equally slected and used for training</span>
[~, ind_sort] = sort(condnum_all);
ind_use = ind_all(ind_sort(1 : 5), :);
condnum_use = condnum_all(ind_sort(1 : 5));
angerr_use = angerr_all(ind_sort(1 : 5));
rotang_use = rotang_all(ind_sort(1 : 5), :);

figure; <span class="comment">% display two selected sets of 6 optimal directions</span>
<span class="keyword">for</span> ii = 1 : 2
    subplot(1, 2, ii)
    plot3(dirs_vis(:, 1), dirs_vis(:, 2), dirs_vis(:, 3), <span class="string">'.'</span>); <span class="comment">% all dirs</span>
    hold <span class="string">on</span>

    visdirs_use = dirs_vis(ind_use(ii, :), :);
    plot3(visdirs_use(:, 1), visdirs_use(:, 2), visdirs_use(:, 3), <span class="string">'o'</span>); <span class="comment">% selected dirs</span>

    R = rot3d(rotang_use(ii, :));
    dsm6_rot = (R * dsm6_norm')';
    dsm6_rot_vis = dsm6_rot .* sign(dsm6_rot(:, 3));
    plot3(dsm6_rot_vis(:, 1), dsm6_rot_vis(:, 2), dsm6_rot_vis(:, 3), <span class="string">'x'</span>); <span class="comment">% rotated DSM6 dirs</span>

    grid <span class="string">on</span>, axis <span class="string">equal</span>
    xlim([-1, 1])
    ylim([-1, 1])
    zlim([-1, 1])
    title([<span class="string">'cond num='</span> num2str(condnum_use(ii))]);
<span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="s_DeepDTI_prepData_03.png" alt=""> <h2 id="4">generate input data of CNN</h2><pre class="codeinput">input_all = {};
tensor_all = {};
bval_synth = 1000; <span class="comment">% b value for synthesized dwis</span>

<span class="keyword">for</span> ii = 1 : 5
    b0 = b0s(:, :, :, ii); <span class="comment">% a single b=0 image for each set of selected 6 dwis</span>
    dwis6 = dwis(:, :, :, ind_use(ii, :));
    bvals6 = bvals_dwi(ind_use(ii, :));
    bvecs6 = bvecs_dwi(ind_use(ii, :), :);

    <span class="comment">% compute apparent diffusion coefficients</span>
    adcs6 = log(dwis6 ./ b0); <span class="comment">% s = s0 * exp(-b * adc)</span>
    <span class="keyword">for</span> jj = 1 : length(bvals6)
        adcs6(:, :, :, jj) = adcs6(:, :, :, jj) / (-bvals6(jj)); <span class="comment">% in case bvalues might be different for acquired dwis</span>
    <span class="keyword">end</span>

    <span class="comment">% compute tensors</span>
    adcs6_vec = reshape(adcs6, sz_data(1)*sz_data(2)*sz_data(3), size(adcs6, 4)); <span class="comment">% transform volume data to vectors</span>
    A = amatrix(bvecs6); <span class="comment">% tensor transformation matrix</span>
    tensor_vec = A \ adcs6_vec'; <span class="comment">%i.e., inv(A) * adcs_vec'; solve Ax = b</span>
    tensor = reshape(tensor_vec', [sz_data(1:3), 6]); <span class="comment">% transform tensors in vector form to volume</span>
    tensor(isnan(tensor)) = 0;
    tensor(isinf(tensor)) = 0;
    tensor_all{ii} = tensor;

    <span class="comment">% synthesize dwis along DSM6 dirs</span>
    dwis6norm_vec_synth = exp(-bval_synth .* amatrix(dsm6_norm) * tensor_vec); <span class="comment">% normalized dwi</span>
    dwis6_synth = b0 .* reshape(dwis6norm_vec_synth', [sz_data(1:3), size(dwis6norm_vec_synth, 1)]);
    dwis6_synth(isnan(dwis6_synth)) = 0;
    dwis6_synth(isinf(dwis6_synth)) = 0;

    diff_input = cat(4, b0, dwis6_synth);
    input_all{ii} = diff_input;
<span class="keyword">end</span>

figure; <span class="comment">% display synthesized dwis</span>
<span class="keyword">for</span> ii = 1 : 2
    diff_input = input_all{ii};
    subplot(1, 2, ii)
    imshow(rot90(diff_input(:, :, 35, 2)), [0, 4000])
    title(<span class="string">'synthsized dwi'</span>);
<span class="keyword">end</span>

figure; <span class="comment">% display synthesized dwis</span>
<span class="keyword">for</span> ii = 1 : 2
    tensor = tensor_all{ii};
    subplot(1, 2, ii)

    dtimetrics = decompose_tensor(tensor, mask);
    fa = dtimetrics.fa;
    imshow(rot90(fa(:, :, 35)), [0, 1])
    title(<span class="string">'fractional anisotropy'</span>);
<span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="s_DeepDTI_prepData_04.png" alt=""> <img vspace="5" hspace="5" src="s_DeepDTI_prepData_05.png" alt=""> <h2 id="5">generate ground-truth data of CNN</h2><pre class="codeinput"><span class="comment">% compute apparent diffusion coefficients</span>
adcs = log(dwis ./ meanb0); <span class="comment">% s = b0 * exp(-b * adc)</span>
<span class="keyword">for</span> ii = 1 : size(adcs, 4)
    adcs(:, :, :, ii) = adcs(:, :, :, ii) / (-bvals_dwi(ii)); <span class="comment">% in case bvalues might be different for acquired dwis</span>
<span class="keyword">end</span>

adcs_vec = reshape(adcs, sz_data(1)*sz_data(2)*sz_data(3), size(adcs, 4)); <span class="comment">% tx volume data to vectors</span>
tensor_gt_vec = amatrix(bvecs_dwi) \ adcs_vec'; <span class="comment">% solve tensors</span>
tensor_gt = reshape(tensor_gt_vec', [sz_data(1:3), 6]); <span class="comment">% tx vectors to volume</span>
tensor_gt(isnan(tensor_gt)) = 0;
tensor_gt(isinf(tensor_gt)) = 0;

<span class="comment">% synthesize dwis along DSM6 dirs</span>
dwis6norm_vec_gt = exp(-bval_synth .* amatrix(dsm6_norm) * tensor_gt_vec);
dwis6_gt = b0 .* reshape(dwis6norm_vec_gt', [sz_data(1:3), size(dwis6norm_vec_gt, 1)]);
dwis6_gt(isnan(dwis6_gt)) = 0;
dwis6_gt(isinf(dwis6_gt)) = 0;

diff_gt = cat(4, meanb0, dwis6_gt);

figure; <span class="comment">% display ground-truth dwi and fa</span>
subplot(1, 2, 1)
imshow(rot90(diff_gt(:, :, 35, 2)), [0, 4000])
title(<span class="string">'ground-truth dwi'</span>);

dtimetrics = decompose_tensor(tensor_gt, mask);
fa = dtimetrics.fa;
subplot(1, 2, 2)
imshow(rot90(fa(:, :, 35)), [0, 1])
title(<span class="string">'ground-truth fa'</span>);

figure; <span class="comment">% display residuals btx input dwis and ground truth</span>
<span class="keyword">for</span> ii = 1 : 2
    diff_input = input_all{ii};
    subplot(1, 2, ii)
    imagesc(rot90(diff_gt(:, :, 35, 2)) - rot90(diff_input(:, :, 35, 2)), [-1000, 1000])
    axis <span class="string">image</span>
    title(<span class="string">'residual image'</span>);
    colormap(bgr_colormap);
    colorbar;
<span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="s_DeepDTI_prepData_06.png" alt=""> <img vspace="5" hspace="5" src="s_DeepDTI_prepData_07.png" alt=""> <h2 id="6">save data</h2><pre class="codeinput"><span class="comment">% data is saved in unit16 to save sapce to be shared on Github.</span>
<span class="comment">% actual implemenation should use floating point to maintain precision.</span>
<span class="comment">% these input and output data can be used to train any CNN for denoising.</span>
diff_input1 = uint16(input_all{1});
diff_input2 = uint16(input_all{2});
diff_input3 = uint16(input_all{3});
diff_input4 = uint16(input_all{4});
diff_input5 = uint16(input_all{5});
diff_gt = uint16(diff_gt);

save(<span class="string">'cnn_inout.mat'</span>, <span class="string">'diff_input1'</span>, <span class="string">'diff_input2'</span>, <span class="string">'diff_input3'</span>, <span class="keyword">...</span>
         <span class="string">'diff_input4'</span>, <span class="string">'diff_input5'</span>, <span class="string">'diff_gt'</span>, <span class="string">'mask'</span>);
</pre><p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2018a</a><br></p></div><!--
##### SOURCE BEGIN #####
%% introduction

% s_DeepDTI_prepData.m
% 
%   A script for preparing input and output data for convolutional neural
%   network in DeepDTI.
%
%   Source code:
%       https://github.com/qiyuantian/DeepDTI/blob/main/s_DeepDTI_prepData.m
%
%   HTML file can be automatically generaged using command:
%       publish('s_DeepDTI_prepData.m', 'html');
%
%   Reference:
%       [1] Tian Q, Bilgic B, Fan Q, Liao C, Ngamsombat C, Hu Y, Witzel T,
%       Setsompop K, Polimeni JR, Huang SY. DeepDTI: High-fidelity
%       six-direction diffusion tensor imaging using deep learning.
%       NeuroImage. 2020;219:117017. 
%
%       [2] Tian Q, Li Z, Fan Q, Ngamsombat C, Hu Y, Liao C, Wang F,
%       Setsompop K, Polimeni JR, Bilgic B, Huang SY. SRDTI: Deep
%       learning-based super-resolution for diffusion tensor MRI. arXiv
%       preprint. 2021; arXiv:2102.09069.
%
% (c) Qiyuan Tian, Harvard, 2021

%% load data

clear, clc, close all

tmp = load('data.mat'); % example data was saved in unit16 to save sapce to be shared on Github.
data = double(tmp.data); % 18 b = 0 volumes and 90 dwi volumes
% due to size limit of github, only 70 axial slices are used here as
% example data. actual implementation should use whole brain data. 
% diffusion data were corrected for intensity bias already, which can be 
% performed for new data using dwibiascorrect function from MRtrix3:
% https://mrtrix.readthedocs.io/en/latest/reference/commands/dwibiascorrect.html
% we did not evaluate the effects of bias on the performance of CNN, but do
% not expect significant difference in results.
bvals = tmp.bvals; % b = 1000 s/mm^2
bvecs = tmp.bvecs;
mask = tmp.mask;

b0s = data(:, :, :, bvals < 100); % all 18 b = 0 images
meanb0 = mean(b0s, 4); % mean b = 0 images
dwis = data(:, :, :, bvals > 100); % all 90 dwis
bvals_dwi = bvals(bvals > 100); % bvals for dwis
bvecs_dwi = bvecs(bvals > 100, :); % bvecs for dwis

dirs = bvecs(bvals > 100, :); % 90 diffusion-encoding directions
dirs_vis = dirs .* sign(dirs(:, 3)); % directions flipped to z > 0 for visualization
sz_data = size(data);

figure; % display image data
subplot(1, 2, 1)
imshow(rot90(data(:, :, 35, 1)), [0, 10000])
title('b = 0 image');
subplot(1, 2, 2)
imshow(rot90(data(:, :, 35, 2)), [0, 4000])
title('diffusion weighted image');

figure; % display diffusion encoding directions, all flipped to z > 0 
plot3(dirs_vis(:, 1), dirs_vis(:, 2), dirs_vis(:, 3), '.');
grid on, axis equal
zlim([-1, 1])
title('90 diffusion encoding directions');

%% select optimized encoding directions

% 6 optimized directions from the DSM scheme that minimize the condition
% number of the diffusion tensor transformation matrix while are as uniform 
% as possible. from S Skare et al., J Magn Reson. 2000;147(2):340-52.
dsm6 = [0.91, 0.416, 0; ...
               0, 0.91, 0.416; ...
               0.416, 0, 0.91; ...
               0.91, -0.416, 0; ...
               0, 0.91, -0.416; ...
              -0.416, 0, 0.91];

dsm6_norm = dsm6 ./ sqrt(dsm6(:, 1) .^ 2 + dsm6(:, 2) .^ 2 + dsm6(:, 3) .^ 2); % normalize vectors

% randomly rotate the DSM6 dirs, select their nearest 6 dirs from acquired
% dirs, keep those with low condition number and angel difference.
rotang_all = [];
angerr_all  = [];
condnum_all = [];
ind_all = [];
for ii = 1 : 100000 % number of iterations can be increased in actual implementation
    
    rotangs = rand(1, 3) * 2 * pi; % random angles to rotate around x, y, z axis
    R = rot3d(rotangs); % rotation matrix
    dsm6_rot = (R * dsm6_norm')'; % roated directions
   
    % find 6 nearest dirs in acquired dirs
    angerrors = acosd(abs(dsm6_rot * dirs')); % angles btw rotated DSM6 dirs and acquired dirs
    [minerrors, ind] = min(angerrors, [], 2); % 6 dirs with min angles compared to rotated DSM6 dirs

    meanangerr = mean(minerrors); % mean angle errors of selected dirs
    condnum = cond(amatrix(dirs(ind, :))); % cond number of tensor tx matrix of selected dirs
    
    if meanangerr < 5 && condnum < 1.6 % only use dirs with low angle error and cond number
        if isempty(ind_all) || ~any(sum(ind_all == sort(ind'), 2) == 6) % make sure no repetition
            
            % record params for satisfied sets
            angerr_all = cat(1, angerr_all, meanangerr);
            condnum_all = cat(1, condnum_all, condnum);
            ind_all = cat(1, ind_all, sort(ind'));
            rotang_all = cat(1, rotang_all, rotangs);
        end
    end
end

% here only select 5 sets of directions with lowest condition number
% better to make sure all dwis can be equally slected and used for training 
[~, ind_sort] = sort(condnum_all);
ind_use = ind_all(ind_sort(1 : 5), :);
condnum_use = condnum_all(ind_sort(1 : 5));
angerr_use = angerr_all(ind_sort(1 : 5));
rotang_use = rotang_all(ind_sort(1 : 5), :);

figure; % display two selected sets of 6 optimal directions
for ii = 1 : 2
    subplot(1, 2, ii)
    plot3(dirs_vis(:, 1), dirs_vis(:, 2), dirs_vis(:, 3), '.'); % all dirs
    hold on
    
    visdirs_use = dirs_vis(ind_use(ii, :), :);
    plot3(visdirs_use(:, 1), visdirs_use(:, 2), visdirs_use(:, 3), 'o'); % selected dirs
    
    R = rot3d(rotang_use(ii, :));
    dsm6_rot = (R * dsm6_norm')';
    dsm6_rot_vis = dsm6_rot .* sign(dsm6_rot(:, 3));
    plot3(dsm6_rot_vis(:, 1), dsm6_rot_vis(:, 2), dsm6_rot_vis(:, 3), 'x'); % rotated DSM6 dirs
    
    grid on, axis equal
    xlim([-1, 1])
    ylim([-1, 1])
    zlim([-1, 1])
    title(['cond num=' num2str(condnum_use(ii))]);
end

%% generate input data of CNN
input_all = {};
tensor_all = {};
bval_synth = 1000; % b value for synthesized dwis

for ii = 1 : 5
    b0 = b0s(:, :, :, ii); % a single b=0 image for each set of selected 6 dwis
    dwis6 = dwis(:, :, :, ind_use(ii, :));
    bvals6 = bvals_dwi(ind_use(ii, :));
    bvecs6 = bvecs_dwi(ind_use(ii, :), :);
    
    % compute apparent diffusion coefficients
    adcs6 = log(dwis6 ./ b0); % s = s0 * exp(-b * adc) 
    for jj = 1 : length(bvals6)
        adcs6(:, :, :, jj) = adcs6(:, :, :, jj) / (-bvals6(jj)); % in case bvalues might be different for acquired dwis
    end
    
    % compute tensors
    adcs6_vec = reshape(adcs6, sz_data(1)*sz_data(2)*sz_data(3), size(adcs6, 4)); % transform volume data to vectors
    A = amatrix(bvecs6); % tensor transformation matrix
    tensor_vec = A \ adcs6_vec'; %i.e., inv(A) * adcs_vec'; solve Ax = b
    tensor = reshape(tensor_vec', [sz_data(1:3), 6]); % transform tensors in vector form to volume
    tensor(isnan(tensor)) = 0;
    tensor(isinf(tensor)) = 0;
    tensor_all{ii} = tensor;

    % synthesize dwis along DSM6 dirs
    dwis6norm_vec_synth = exp(-bval_synth .* amatrix(dsm6_norm) * tensor_vec); % normalized dwi
    dwis6_synth = b0 .* reshape(dwis6norm_vec_synth', [sz_data(1:3), size(dwis6norm_vec_synth, 1)]);    
    dwis6_synth(isnan(dwis6_synth)) = 0;
    dwis6_synth(isinf(dwis6_synth)) = 0;
    
    diff_input = cat(4, b0, dwis6_synth);
    input_all{ii} = diff_input;
end

figure; % display synthesized dwis
for ii = 1 : 2
    diff_input = input_all{ii};
    subplot(1, 2, ii)
    imshow(rot90(diff_input(:, :, 35, 2)), [0, 4000])
    title('synthsized dwi');
end

figure; % display synthesized dwis
for ii = 1 : 2
    tensor = tensor_all{ii};
    subplot(1, 2, ii)
    
    dtimetrics = decompose_tensor(tensor, mask);
    fa = dtimetrics.fa;
    imshow(rot90(fa(:, :, 35)), [0, 1])
    title('fractional anisotropy');
end

%% generate ground-truth data of CNN

% compute apparent diffusion coefficients
adcs = log(dwis ./ meanb0); % s = b0 * exp(-b * adc)
for ii = 1 : size(adcs, 4)
    adcs(:, :, :, ii) = adcs(:, :, :, ii) / (-bvals_dwi(ii)); % in case bvalues might be different for acquired dwis
end

adcs_vec = reshape(adcs, sz_data(1)*sz_data(2)*sz_data(3), size(adcs, 4)); % tx volume data to vectors
tensor_gt_vec = amatrix(bvecs_dwi) \ adcs_vec'; % solve tensors
tensor_gt = reshape(tensor_gt_vec', [sz_data(1:3), 6]); % tx vectors to volume
tensor_gt(isnan(tensor_gt)) = 0;
tensor_gt(isinf(tensor_gt)) = 0;

% synthesize dwis along DSM6 dirs
dwis6norm_vec_gt = exp(-bval_synth .* amatrix(dsm6_norm) * tensor_gt_vec);
dwis6_gt = b0 .* reshape(dwis6norm_vec_gt', [sz_data(1:3), size(dwis6norm_vec_gt, 1)]);    
dwis6_gt(isnan(dwis6_gt)) = 0;
dwis6_gt(isinf(dwis6_gt)) = 0;

diff_gt = cat(4, meanb0, dwis6_gt);

figure; % display ground-truth dwi and fa
subplot(1, 2, 1)
imshow(rot90(diff_gt(:, :, 35, 2)), [0, 4000])
title('ground-truth dwi');
    
dtimetrics = decompose_tensor(tensor_gt, mask);
fa = dtimetrics.fa;
subplot(1, 2, 2)
imshow(rot90(fa(:, :, 35)), [0, 1])
title('ground-truth fa');

figure; % display residuals btx input dwis and ground truth
for ii = 1 : 2
    diff_input = input_all{ii};
    subplot(1, 2, ii)
    imagesc(rot90(diff_gt(:, :, 35, 2)) - rot90(diff_input(:, :, 35, 2)), [-1000, 1000])
    axis image
    title('residual image');
    colormap(bgr_colormap);
    colorbar;
end

%% save data

% data is saved in unit16 to save sapce to be shared on Github.
% actual implemenation should use floating point to maintain precision.
% these input and output data can be used to train any CNN for denoising.
diff_input1 = uint16(input_all{1});
diff_input2 = uint16(input_all{2});
diff_input3 = uint16(input_all{3});
diff_input4 = uint16(input_all{4});
diff_input5 = uint16(input_all{5});
diff_gt = uint16(diff_gt);

save('cnn_inout.mat', 'diff_input1', 'diff_input2', 'diff_input3', ...
         'diff_input4', 'diff_input5', 'diff_gt', 'mask');

##### SOURCE END #####
--></body></html>